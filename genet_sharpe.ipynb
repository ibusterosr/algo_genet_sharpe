{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, json\n",
    "import numpy as np\n",
    "import random\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://miax-gateway-jog4ew3z3q-ew.a.run.app'\n",
    "competi = 'mia_10'\n",
    "user_key = 'AIzaSyDMTpNC68E6xjWBWVOWh61i7EvzduUit2Y'\n",
    "market = 'IBEX'\n",
    "competi = 'mia_10'\n",
    "algo_tag = 'ibusteros_algo3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_master():\n",
    "    url = f'{url_base}/data/ticker_master'\n",
    "    params = {\n",
    "        'competi': competi,\n",
    "        'market': 'IBEX',\n",
    "        'key': user_key\n",
    "        }\n",
    "    response = requests.get(url, params)\n",
    "    tk_master = response.json()\n",
    "    maestro_df = pd.DataFrame(tk_master['master'])\n",
    "    return maestro_df\n",
    "\n",
    "def get_close_data(tck):\n",
    "    url2 = f'{url_base}/data/time_series'\n",
    "    params = {\n",
    "        'market': 'IBEX',\n",
    "        'key': user_key,\n",
    "        'ticker': tck,\n",
    "        'close': True\n",
    "        }\n",
    "    response = requests.get(url2, params)\n",
    "    tk_data = response.json()\n",
    "    series_data = pd.read_json(tk_data, typ='series')\n",
    "    return series_data\n",
    "\n",
    "def get_ohlc_data(tck):\n",
    "    url2 = f'{url_base}/data/time_series'\n",
    "    params = {\n",
    "        'market': 'IBEX',\n",
    "        'key': user_key,\n",
    "        'ticker': tck,\n",
    "        'close': False\n",
    "        }\n",
    "    response = requests.get(url2, params)\n",
    "    tk_data = response.json()\n",
    "    series_data = pd.read_json(tk_data, typ='series')\n",
    "    return series_data\n",
    "\n",
    "def get_df_close(df_maestro):\n",
    "    data_close_all = {}\n",
    "    for _,row in df_maestro.iterrows():\n",
    "        tick = row.ticker\n",
    "        #print(f'Downloading: {tick}...')\n",
    "        close_data = get_close_data(tick)\n",
    "        data_close_all[tick] = close_data\n",
    "\n",
    "    return(pd.DataFrame(data_close_all))\n",
    "\n",
    "def send_alloc(algo_tag, date, allocation):\n",
    "    url = f'{url_base}/participants/allocation?key={user_key}'\n",
    "    data = {\n",
    "    'competi': competi,\n",
    "    'algo_tag': algo_tag,\n",
    "    'market': market,\n",
    "    'date': date,\n",
    "    'allocation': allocation\n",
    "        }\n",
    "    response = requests.post(url, data=json.dumps(data))\n",
    "    print(response.text)\n",
    "\n",
    "def allocs_to_frame(json_allocations):\n",
    "        alloc_list = []\n",
    "        for json_alloc in json_allocations:\n",
    "            #print(json_alloc)\n",
    "            allocs = pd.DataFrame(json_alloc['allocations'])\n",
    "            allocs.set_index('ticker', inplace=True)\n",
    "            alloc_serie = allocs['alloc']\n",
    "            alloc_serie.name = json_alloc['date'] \n",
    "            alloc_list.append(alloc_serie)\n",
    "        all_alloc_df = pd.concat(alloc_list, axis=1).T\n",
    "        return all_alloc_df\n",
    "\n",
    "def get_allocs(algo_tag):\n",
    "        url = f'{url_base}/participants/algo_allocations'\n",
    "        params = {\n",
    "            'key':user_key,\n",
    "            'competi': competi,\n",
    "            'algo_tag': algo_tag,\n",
    "            'market': market,\n",
    "        }\n",
    "        response = requests.get(url, params)\n",
    "        return allocs_to_frame(response.json())\n",
    "\n",
    "def delete_allocs(algo_tag):\n",
    "        url = f'{url_base}/participants/delete_allocations'\n",
    "        url_auth = f'{url}?key={user_key}'\n",
    "        params = {\n",
    "            'competi': competi,\n",
    "            'algo_tag': algo_tag,\n",
    "            'market': market,\n",
    "            }\n",
    "        response = requests.post(url_auth, data=json.dumps(params))\n",
    "        print(response.status_code)\n",
    "     \n",
    "\n",
    "\n",
    "def get_algos():\n",
    "    url = f'{url_base}/participants/algorithms'\n",
    "    params = {\n",
    "        'competi': competi,\n",
    "        'key': user_key\n",
    "    }\n",
    "    response = requests.get(url, params)\n",
    "    algos = response.json()\n",
    "    algos_df = pd.DataFrame(algos)\n",
    "    return algos_df\n",
    "\n",
    "\n",
    "def exec_algo(algo_tag):\n",
    "        url = f'{url_base}/participants/exec_algo?key={user_key}'\n",
    "        params = {\n",
    "            'competi': competi,\n",
    "            'algo_tag': algo_tag,\n",
    "            'market': market,\n",
    "        }\n",
    "        response = requests.post(url, data=json.dumps(params))\n",
    "        if response.status_code == 200:\n",
    "            exec_data = response.json()\n",
    "            status = exec_data.get('status')\n",
    "            print(status)\n",
    "            res_data = exec_data.get('content')\n",
    "            if res_data:\n",
    "                metrics = pd.Series(res_data['result'])\n",
    "                trades = pd.DataFrame(res_data['trades'])\n",
    "                return metrics, trades\n",
    "        else:\n",
    "            exec_data = dict()\n",
    "            print(response.text)\n",
    "\n",
    "def get_exec_results(algo_tag):\n",
    "        url = f'{url_base}/participants/algo_exec_results'\n",
    "        params = {\n",
    "            'key': user_key,\n",
    "            'competi': competi,\n",
    "            'algo_tag': algo_tag,\n",
    "            'market': market,\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params)\n",
    "        exec_data = response.json()\n",
    "        print(exec_data.get('status'))\n",
    "        res_data = exec_data.get('content')\n",
    "        if res_data:\n",
    "            metrics = pd.Series(res_data['result'])\n",
    "            trades = pd.DataFrame(res_data['trades'])\n",
    "            return metrics, trades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_master = get_ticker_master()\n",
    "df_close = get_df_close(t_master)\n",
    "df_rets = np.log(df_close).diff().iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS GENETIC ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_marko(long, n_reps):\n",
    "    \"\"\"\n",
    "    Genera una matriz de pesos normalizados al azar para un modelo Markoviano.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    long : int\n",
    "        La longitud de la matriz de pesos.\n",
    "    n_reps : int\n",
    "        El número de repeticiones para generar la matriz de pesos.\n",
    "\n",
    "    Devuelve:\n",
    "    ---------\n",
    "    mat_pesos_norm : numpy.ndarray\n",
    "        La matriz de pesos normalizados al azar para un modelo Markoviano.\n",
    "\n",
    "    Notas:\n",
    "    ------\n",
    "    Esta función permite a los pesos tener ceros en algunos de los fondos del portfolio.\n",
    "    \"\"\"\n",
    "\n",
    "    # Genera una matriz de pesos y una matriz binaria aleatoria del mismo tamaño\n",
    "    mat_pesos = np.random.uniform(0, 1, (n_reps, long))\n",
    "    matrix_01 = np.random.randint(0, 2, size=(n_reps, long))\n",
    "\n",
    "    # Multiplica la matriz de pesos con la matriz binaria para crear una matriz aleatoria \n",
    "    # con algunos elementos de la matriz de pesos y otros iguales a cero\n",
    "    m1 = mat_pesos[matrix_01.sum(axis=1) != 0,:] * matrix_01[matrix_01.sum(axis=1) != 0,:]\n",
    "\n",
    "    # Normaliza la matriz de pesos aleatoria resultante para que la suma de los pesos en cada fila sea 1\n",
    "    mat_pesos_norm = m1 / np.sum(m1, axis=1, keepdims=True)\n",
    "    \n",
    "    # Reemplaza los valores NaN en la matriz de pesos normalizados con ceros\n",
    "    mat_pesos_norm = np.nan_to_num(mat_pesos_norm)\n",
    "\n",
    "    return mat_pesos_norm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def best_marko(funds, mean_rents, df_rents, n_reps= 100):\n",
    "    \"\"\"\n",
    "    Encuentra la asignación de pesos óptima para un conjunto de fondos utilizando el modelo Markoviano.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    funds : list\n",
    "        Una lista de los nombres de los fondos.\n",
    "    n_reps : int, opcional (valor predeterminado = 100)\n",
    "        El número de repeticiones para generar la matriz de pesos aleatoria.\n",
    "\n",
    "    Devuelve:\n",
    "    ---------\n",
    "    tuple\n",
    "        Una tupla que contiene la mejor relación riesgo-recompensa, la asignación de pesos óptima \n",
    "        y una lista de los fondos con asignación de peso no nula.\n",
    "\n",
    "    Notas:\n",
    "    ------\n",
    "    Esta función utiliza el modelo Markoviano para encontrar la asignación de pesos óptima \n",
    "    para un conjunto de fondos dados. Se genera una matriz de pesos aleatoria y se calcula \n",
    "    la relación riesgo-recompensa para cada una de las asignaciones de pesos. La asignación \n",
    "    de pesos con la mejor relación riesgo-recompensa se devuelve junto con la relación \n",
    "    riesgo-recompensa correspondiente y una lista de los fondos con asignación de peso no nula.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convierte la lista de fondos en un array numpy\n",
    "    funds = np.array(funds)\n",
    "\n",
    "    # Obtiene la longitud de los fondos y genera una matriz de pesos aleatoria\n",
    "    long = len(funds)\n",
    "    w = weights_marko(long, n_reps)\n",
    "\n",
    "    # Calcula la rentabilidad media y la matriz de covarianza de los fondos\n",
    "    r_bar = np.array(mean_rents[funds])\n",
    "    mat_cov = df_rents.loc[:, funds].cov()\n",
    "\n",
    "    # Calcula la rentabilidad esperada y la volatilidad para cada asignación de pesos\n",
    "    v_rents = np.dot(w, r_bar)\n",
    "    m1 = np.dot(w, np.array(mat_cov))\n",
    "    v_risk = np.sqrt((m1 * w).sum(axis=1))\n",
    "\n",
    "    # Calcula la relación riesgo-recompensa para cada asignación de pesos\n",
    "    efic = v_rents / v_risk\n",
    "\n",
    "    # Encuentra la asignación de pesos con la mejor relación riesgo-recompensa\n",
    "    best_weight = w[efic.argmax()]\n",
    "    l_fond_0 = funds[best_weight > 0]\n",
    "    best_sharpe = efic[efic.argmax()]\n",
    "\n",
    "    return best_sharpe, best_weight, l_fond_0\n",
    "\n",
    "\n",
    "\n",
    "def select_parents(n_indiv_inic, mean_rents, df_rents, min_fond=1, max_fond=20):\n",
    "    \"\"\"\n",
    "    Selecciona los padres para la siguiente generación.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_indiv_inic : int\n",
    "        Número de individuos iniciales a crear.\n",
    "    min_fond : int, optional\n",
    "        Número mínimo de fondos en la selección de fondos aleatorios, por defecto 1.\n",
    "    max_fond : int, optional\n",
    "        Número máximo de fondos en la selección de fondos aleatorios, por defecto 20.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    parent_funds : numpy.ndarray\n",
    "        Array de fondos de inversión de los padres seleccionados para la siguiente generación.\n",
    "    best_parent : numpy.ndarray\n",
    "        Array de fondos de inversión del mejor padre de la generación actual.\n",
    "    best_parent_sharpe : float\n",
    "        Ratio Sharpe del mejor padre de la generación actual.\n",
    "    \"\"\"\n",
    "\n",
    "    invest_funds = list()\n",
    "    #final_weights = list()\n",
    "    fitness = list()\n",
    "\n",
    "    #n_fond = np.random.randint(min_fond, max_fond, size=n_indiv_inic)\n",
    "    fondos_20 = np.random.choice(df_rents.columns, size=(n_indiv_inic,max_fond))\n",
    "    matrix_01 = np.random.choice([True, False], size=(n_indiv_inic,max_fond))\n",
    "\n",
    "    fondos_20 = fondos_20[matrix_01.sum(axis=1) != 0,:]\n",
    "    matrix_01 = matrix_01[matrix_01.sum(axis=1) != 0,:]\n",
    "\n",
    "    for i in range(len(fondos_20)):\n",
    "        l_fond = fondos_20[i][matrix_01[i]]\n",
    "        #print(f'long inic: {len(l_fond)}')\n",
    "        #l_fond = random.sample(df_close.columns.tolist(), n_fond[i])\n",
    "        sh, _, l_fond_0 = best_marko(l_fond, mean_rents, df_rents)\n",
    "        #print(f'long final: {len(l_fond_0)}')\n",
    "        #print('-------------')\n",
    "        \n",
    "        \n",
    "        fitness.append(sh)\n",
    "        #final_weights.append(w)\n",
    "        invest_funds.append(l_fond_0)\n",
    "\n",
    "    fitness_norm = (np.array(fitness) - min(fitness)) / (max(fitness)-min(fitness))\n",
    "    thresh = random.uniform(0,1)\n",
    "    #print(f'umbral: {thresh}, mediana de fitness_norm {np.median(fitness_norm)}')\n",
    "\n",
    "    fitness_norm = np.array(fitness_norm, dtype=object)\n",
    "    invest_funds = np.array(invest_funds, dtype=object)\n",
    "    #final_weights = np.array(final_weights, dtype=object)\n",
    "\n",
    "    best_parent = invest_funds[fitness_norm.argmax()]\n",
    "    best_parent_sharpe = fitness[fitness_norm.argmax()]\n",
    "\n",
    "    mask_parent = fitness_norm > thresh\n",
    "    parent_funds = invest_funds[mask_parent]\n",
    "    #print(f'longitud de la generacion: {len(parent_funds)}')\n",
    "    #parent_weights = final_weights[mask_parent]\n",
    "\n",
    "    return parent_funds, best_parent, best_parent_sharpe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def combine_nextgen(parent1, l_parent2, df_rents):\n",
    "    \"\"\"\n",
    "    Combina el primer padre con una lista de segundos padres para generar la siguiente generación.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent1 : array-like\n",
    "        Lista de fondos del primer padre.\n",
    "    l_parent2 : array-like\n",
    "        Lista de listas de fondos de los segundos padres.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        Lista de fondos combinados con el padre con el que tiene una mayor correlación.\n",
    "\n",
    "    \"\"\"\n",
    "    val_parent = list()\n",
    "\n",
    "    for p2 in l_parent2:\n",
    "        funds_p = np.union1d(parent1, p2)\n",
    "        val = abs(df_rents.loc[:,funds_p].corr()).mean().mean()\n",
    "        val_parent.append(val)\n",
    "\n",
    "    val_parent = np.array(val_parent)\n",
    "    #print(val_parent)\n",
    "    #print(f'se ha juntado con el padre nº {val_parent.argmin()}')\n",
    "    #print(f'en particular con el {val_parent.argmin()}º')\n",
    "\n",
    "    return np.union1d(parent1, l_parent2[val_parent.argmin()])\n",
    "\n",
    "\n",
    "\n",
    "def generate_couples(parent_funds, df_rents, n_hijos=100, n_azar=3):\n",
    "    \"\"\"\n",
    "    Genera parejas de fondos para la siguiente generación a partir de los padres de la actual generación.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent_funds : array-like\n",
    "        Lista de arrays de fondos de inversión de la generación anterior.\n",
    "    n_hijos : int, optional\n",
    "        Número de parejas de fondos a generar (default is 100).\n",
    "    n_azar : int, optional\n",
    "        Número de padres aleatorios para combinar con cada padre seleccionado (default is 3).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Lista de arrays de fondos de inversión que representan las parejas de fondos de la siguiente generación.\n",
    "    \"\"\"\n",
    "    couples = list()\n",
    "\n",
    "    # Seleccionar padres y candidatos aleatoriamente\n",
    "    padres = np.random.randint(len(parent_funds), size=n_hijos)\n",
    "    candidatos = np.random.randint(len(parent_funds), size=(n_hijos,n_azar))\n",
    "\n",
    "    # Generar parejas de fondos combinando padres y candidatos\n",
    "    for i in range(n_hijos):\n",
    "        parent1 = parent_funds[padres[i]]\n",
    "        #print(f'se ha juntado el: {padres[i]}')\n",
    "        l_parent2 = parent_funds[candidatos[i]]\n",
    "        #print(f'con alguno de los padres {candidatos[i]}')\n",
    "\n",
    "        # Combinar padres y candidatos para generar la nueva pareja de fondos\n",
    "        couple = combine_nextgen(parent1, l_parent2, df_rents) # emparejamiento variado inverso\n",
    "        couples.append(couple)\n",
    "        #print(f'----------------------')\n",
    "\n",
    "    return couples\n",
    "\n",
    "\n",
    "def create_next_gen(best_parent, best_parent_sharpe, couples, mean_rents, df_rents, n_explore=4):\n",
    "    \"\"\"\n",
    "    Crea la siguiente generación de individuos a partir de los padres y las parejas creadas en la generación anterior.\n",
    "\n",
    "    Parámetros:\n",
    "    - best_parent: numpy array de strings. Fondos de inversión que conforman el mejor individuo de la generación anterior.\n",
    "    - best_parent_sharpe: float. Sharpe ratio del mejor individuo de la generación anterior.\n",
    "    - couples: lista de numpy arrays de strings. Pares de fondos de inversión que han sido seleccionados como padres de la siguiente generación.\n",
    "    - n_explore: int. Número de nuevos fondos que se añadirán a cada hijo de la siguiente generación.\n",
    "\n",
    "    Return:\n",
    "    - ng_sharpe: numpy array de floats. Sharpe ratio de cada individuo de la siguiente generación.\n",
    "    - next_gen_funds: numpy array de numpy arrays de strings. Fondos de inversión que conforman cada individuo de la siguiente generación.\n",
    "    \"\"\"\n",
    "    next_gen_funds = list()\n",
    "    ng_sharpe = list()\n",
    "\n",
    "    next_gen_funds.append(best_parent) # el mejor de la generacion anterior\n",
    "    ng_sharpe.append(best_parent_sharpe)\n",
    "\n",
    "    new_fonds = np.random.choice(df_rents.columns.tolist(), size=(len(couples),n_explore)) # los nuevos fondos a explorar\n",
    "\n",
    "    for i in range(len(couples)):\n",
    "        #print(f'la preja es: {couples[i]}')\n",
    "        fond_son = np.union1d(couples[i], new_fonds[i])\n",
    "        #print(f'con los nuevos fondos es: {fond_son}')\n",
    "\n",
    "        sh,w,hijo = best_marko(fond_son,mean_rents,df_rents)\n",
    "        #print(f'tras aplicar markowitz: {hijo}')\n",
    "        #print(f'----------------------')\n",
    "\n",
    "        ng_sharpe.append(sh)\n",
    "        next_gen_funds.append(hijo)\n",
    "\n",
    "    next_gen_funds = np.array(next_gen_funds, dtype=object)\n",
    "    ng_sharpe = np.array(ng_sharpe)\n",
    "\n",
    "    return ng_sharpe, next_gen_funds\n",
    "\n",
    "\n",
    "def select_parents_next_gen(ng_sharpe, next_gen_funds):\n",
    "    \"\"\"\n",
    "    Selecciona los padres para la siguiente generación en función de su\n",
    "    función de aptitud y devuelve el mejor padre de la generación anterior\n",
    "    así como los que han pasado el umbral\n",
    "\n",
    "    Args:\n",
    "    - ng_sharpe (array-like): Array de flotantes que representan el valor Sharpe de cada\n",
    "      cartera en la siguiente generación.\n",
    "    - next_gen_funds (array-like): Array de arrays con los fondos de cada cartera en la\n",
    "      siguiente generación.\n",
    "\n",
    "    Returns:\n",
    "    - parent_funds (array-like): Array de arrays con los fondos de los padres seleccionados.\n",
    "    - best_parent (array): Array con los fondos del mejor padre de la generación anterior.\n",
    "    - best_parent_sharpe (float): Valor Sharpe del mejor padre de la generación anterior.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Normalizar la fitness\n",
    "    fitness_norm = (ng_sharpe - min(ng_sharpe))/(max(ng_sharpe)-min(ng_sharpe))\n",
    "    # Seleccionar un umbral aleatorio\n",
    "    thresh = random.uniform(0,1)\n",
    "    # Crear una máscara booleana para los padres que superan el umbral\n",
    "    mask_thresh = fitness_norm > thresh\n",
    "\n",
    "    # Seleccionar los padres que superan el umbral, el mejor y su fitness\n",
    "    parent_funds = next_gen_funds[mask_thresh]\n",
    "    best_parent = next_gen_funds[fitness_norm.argmax()]\n",
    "    best_parent_sharpe = ng_sharpe[fitness_norm.argmax()]\n",
    "\n",
    "    return parent_funds, best_parent, best_parent_sharpe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "['ACX' 'AENA' 'ANA' 'PHM' 'REE'] 1.9355572758267963\n",
      "--------------------------\n",
      "2\n",
      "0\n",
      "['ACX' 'AENA' 'ANA' 'PHM' 'REE'] 1.9355572758267963\n",
      "--------------------------\n",
      "3\n",
      "1\n",
      "['ACX' 'AENA' 'ANA' 'CIE' 'PHM' 'REE'] 1.9596740465328373\n",
      "--------------------------\n",
      "4\n",
      "0\n",
      "['ACX' 'AENA' 'ANA' 'CIE' 'PHM' 'REE'] 1.9596740465328373\n",
      "--------------------------\n",
      "5\n",
      "1\n",
      "['ACX' 'AENA' 'ANA' 'CIE' 'PHM' 'REE'] 1.9596740465328373\n",
      "--------------------------\n",
      "6\n",
      "2\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "7\n",
      "0\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "8\n",
      "1\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "9\n",
      "2\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "10\n",
      "3\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "11\n",
      "4\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "12\n",
      "5\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "13\n",
      "6\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "14\n",
      "7\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "15\n",
      "8\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "16\n",
      "9\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "17\n",
      "10\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "18\n",
      "11\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "19\n",
      "12\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "20\n",
      "13\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n",
      "21\n",
      "14\n",
      "['ACX' 'AENA' 'ANA' 'FER' 'PHM' 'REE'] 2.023142523183408\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f2 = pd.to_datetime('2022-01-01')\n",
    "f1 = f2 - pd.DateOffset(days=15)\n",
    "#df_small = df_close.loc[f1:f2,:].dropna(axis=1)\n",
    "#df = np.log(df_small).diff()\n",
    "df = df_rets.loc[f1:f2,:].dropna(axis=1)\n",
    "mean_r = df.mean()\n",
    "n_indiv_inic=400\n",
    "parent_funds, best_parent, best_parent_sharpe=select_parents(n_indiv_inic=n_indiv_inic, mean_rents=mean_r, df_rents=df, min_fond=1, max_fond=len(mean_r))\n",
    "\n",
    "n_it = 100\n",
    "cont = 0\n",
    "opt = -np.Inf\n",
    "it = 0\n",
    "\n",
    "while cont<15 and it<n_it:\n",
    "    it +=1\n",
    "    print(it)\n",
    "    print(cont)\n",
    "    couples = generate_couples(parent_funds, df_rents=df, n_hijos=100, n_azar=3)\n",
    "    ng_sharpe, next_gen_funds = create_next_gen(best_parent, best_parent_sharpe, couples, mean_rents=mean_r,df_rents=df, n_explore=4)\n",
    "    parent_funds, best_parent, best_parent_sharpe = select_parents_next_gen(ng_sharpe, next_gen_funds)\n",
    "    print(best_parent, best_parent_sharpe)\n",
    "    print('--------------------------')\n",
    "    cont += 1\n",
    "\n",
    "    if best_parent_sharpe>opt:\n",
    "        opt = best_parent_sharpe\n",
    "        cont = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACX' 'ANA' 'PHM' 'REE']\n"
     ]
    }
   ],
   "source": [
    "print(f\"['ACX' 'ANA' 'PHM' 'REE']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total padres: 80\n",
      "['SGRE' 'MEL' 'BKT' 'CIE'] 0.9567458334934221\n"
     ]
    }
   ],
   "source": [
    "print(f'total padres: {len(parent_funds)}')\n",
    "print(best_parent, best_parent_sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples = generate_couples(parent_funds, df_rents=df, n_hijos=100, n_azar=3)\n",
    "ng_sharpe, next_gen_funds = create_next_gen(best_parent, best_parent_sharpe, couples, mean_rents=mean_r,df_rents=df, n_explore=4)\n",
    "parent_funds, best_parent, best_parent_sharpe = select_parents_next_gen(ng_sharpe, next_gen_funds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CIE' 'SGRE'] 1.406508174817915\n"
     ]
    }
   ],
   "source": [
    "print(best_parent, best_parent_sharpe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
