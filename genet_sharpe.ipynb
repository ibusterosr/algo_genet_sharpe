{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, json\n",
    "import numpy as np\n",
    "import random\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://miax-gateway-jog4ew3z3q-ew.a.run.app'\n",
    "competi = 'mia_10'\n",
    "user_key = 'AIzaSyDMTpNC68E6xjWBWVOWh61i7EvzduUit2Y'\n",
    "market = 'IBEX'\n",
    "competi = 'mia_10'\n",
    "algo_tag = 'ibusteros_algo3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_master():\n",
    "    url = f'{url_base}/data/ticker_master'\n",
    "    params = {\n",
    "        'competi': competi,\n",
    "        'market': 'IBEX',\n",
    "        'key': user_key\n",
    "        }\n",
    "    response = requests.get(url, params)\n",
    "    tk_master = response.json()\n",
    "    maestro_df = pd.DataFrame(tk_master['master'])\n",
    "    return maestro_df\n",
    "\n",
    "def get_close_data(tck):\n",
    "    url2 = f'{url_base}/data/time_series'\n",
    "    params = {\n",
    "        'market': 'IBEX',\n",
    "        'key': user_key,\n",
    "        'ticker': tck,\n",
    "        'close': True\n",
    "        }\n",
    "    response = requests.get(url2, params)\n",
    "    tk_data = response.json()\n",
    "    series_data = pd.read_json(tk_data, typ='series')\n",
    "    return series_data\n",
    "\n",
    "def get_ohlc_data(tck):\n",
    "    url2 = f'{url_base}/data/time_series'\n",
    "    params = {\n",
    "        'market': 'IBEX',\n",
    "        'key': user_key,\n",
    "        'ticker': tck,\n",
    "        'close': False\n",
    "        }\n",
    "    response = requests.get(url2, params)\n",
    "    tk_data = response.json()\n",
    "    series_data = pd.read_json(tk_data, typ='series')\n",
    "    return series_data\n",
    "\n",
    "def get_df_close(df_maestro):\n",
    "    data_close_all = {}\n",
    "    for _,row in df_maestro.iterrows():\n",
    "        tick = row.ticker\n",
    "        #print(f'Downloading: {tick}...')\n",
    "        close_data = get_close_data(tick)\n",
    "        data_close_all[tick] = close_data\n",
    "\n",
    "    return(pd.DataFrame(data_close_all))\n",
    "\n",
    "def send_alloc(algo_tag, date, allocation):\n",
    "    url = f'{url_base}/participants/allocation?key={user_key}'\n",
    "    data = {\n",
    "    'competi': competi,\n",
    "    'algo_tag': algo_tag,\n",
    "    'market': market,\n",
    "    'date': date,\n",
    "    'allocation': allocation\n",
    "        }\n",
    "    response = requests.post(url, data=json.dumps(data))\n",
    "    print(response.text)\n",
    "\n",
    "def allocs_to_frame(json_allocations):\n",
    "        alloc_list = []\n",
    "        for json_alloc in json_allocations:\n",
    "            #print(json_alloc)\n",
    "            allocs = pd.DataFrame(json_alloc['allocations'])\n",
    "            allocs.set_index('ticker', inplace=True)\n",
    "            alloc_serie = allocs['alloc']\n",
    "            alloc_serie.name = json_alloc['date'] \n",
    "            alloc_list.append(alloc_serie)\n",
    "        all_alloc_df = pd.concat(alloc_list, axis=1).T\n",
    "        return all_alloc_df\n",
    "\n",
    "def get_allocs(algo_tag):\n",
    "        url = f'{url_base}/participants/algo_allocations'\n",
    "        params = {\n",
    "            'key':user_key,\n",
    "            'competi': competi,\n",
    "            'algo_tag': algo_tag,\n",
    "            'market': market,\n",
    "        }\n",
    "        response = requests.get(url, params)\n",
    "        return allocs_to_frame(response.json())\n",
    "\n",
    "def delete_allocs(algo_tag):\n",
    "        url = f'{url_base}/participants/delete_allocations'\n",
    "        url_auth = f'{url}?key={user_key}'\n",
    "        params = {\n",
    "            'competi': competi,\n",
    "            'algo_tag': algo_tag,\n",
    "            'market': market,\n",
    "            }\n",
    "        response = requests.post(url_auth, data=json.dumps(params))\n",
    "        print(response.status_code)\n",
    "     \n",
    "\n",
    "\n",
    "def get_algos():\n",
    "    url = f'{url_base}/participants/algorithms'\n",
    "    params = {\n",
    "        'competi': competi,\n",
    "        'key': user_key\n",
    "    }\n",
    "    response = requests.get(url, params)\n",
    "    algos = response.json()\n",
    "    algos_df = pd.DataFrame(algos)\n",
    "    return algos_df\n",
    "\n",
    "\n",
    "def exec_algo(algo_tag):\n",
    "        url = f'{url_base}/participants/exec_algo?key={user_key}'\n",
    "        params = {\n",
    "            'competi': competi,\n",
    "            'algo_tag': algo_tag,\n",
    "            'market': market,\n",
    "        }\n",
    "        response = requests.post(url, data=json.dumps(params))\n",
    "        if response.status_code == 200:\n",
    "            exec_data = response.json()\n",
    "            status = exec_data.get('status')\n",
    "            print(status)\n",
    "            res_data = exec_data.get('content')\n",
    "            if res_data:\n",
    "                metrics = pd.Series(res_data['result'])\n",
    "                trades = pd.DataFrame(res_data['trades'])\n",
    "                return metrics, trades\n",
    "        else:\n",
    "            exec_data = dict()\n",
    "            print(response.text)\n",
    "\n",
    "def get_exec_results(algo_tag):\n",
    "        url = f'{url_base}/participants/algo_exec_results'\n",
    "        params = {\n",
    "            'key': user_key,\n",
    "            'competi': competi,\n",
    "            'algo_tag': algo_tag,\n",
    "            'market': market,\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params)\n",
    "        exec_data = response.json()\n",
    "        print(exec_data.get('status'))\n",
    "        res_data = exec_data.get('content')\n",
    "        if res_data:\n",
    "            metrics = pd.Series(res_data['result'])\n",
    "            trades = pd.DataFrame(res_data['trades'])\n",
    "            return metrics, trades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_master = get_ticker_master()\n",
    "df_close = get_df_close(t_master)\n",
    "df_rets = np.log(df_close).diff().iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS GENETIC ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_marko(long, n_reps):\n",
    "    \"\"\"\n",
    "    Genera una matriz de pesos normalizados al azar para un modelo Markoviano.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    long : int\n",
    "        La longitud de la matriz de pesos.\n",
    "    n_reps : int\n",
    "        El número de repeticiones para generar la matriz de pesos.\n",
    "\n",
    "    Devuelve:\n",
    "    ---------\n",
    "    mat_pesos_norm : numpy.ndarray\n",
    "        La matriz de pesos normalizados al azar para un modelo Markoviano.\n",
    "\n",
    "    Notas:\n",
    "    ------\n",
    "    Esta función permite a los pesos tener ceros en algunos de los fondos del portfolio.\n",
    "    \"\"\"\n",
    "\n",
    "    # Genera una matriz de pesos y una matriz binaria aleatoria del mismo tamaño\n",
    "    mat_pesos = np.random.uniform(0, 1, (n_reps, long))\n",
    "    matrix_01 = np.random.randint(0, 2, size=(n_reps, long))\n",
    "\n",
    "    # Multiplica la matriz de pesos con la matriz binaria para crear una matriz aleatoria \n",
    "    # con algunos elementos de la matriz de pesos y otros iguales a cero\n",
    "    m1 = mat_pesos[matrix_01.sum(axis=1) != 0,:] * matrix_01[matrix_01.sum(axis=1) != 0,:]\n",
    "\n",
    "    # Normaliza la matriz de pesos aleatoria resultante para que la suma de los pesos en cada fila sea 1\n",
    "    mat_pesos_norm = m1 / np.sum(m1, axis=1, keepdims=True)\n",
    "    \n",
    "    # Reemplaza los valores NaN en la matriz de pesos normalizados con ceros\n",
    "    mat_pesos_norm = np.nan_to_num(mat_pesos_norm)\n",
    "\n",
    "    return mat_pesos_norm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def best_marko(funds, mean_rents, df_rents, n_reps= 100):\n",
    "    \"\"\"\n",
    "    Encuentra la asignación de pesos óptima para un conjunto de fondos utilizando el modelo Markoviano.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    funds : list\n",
    "        Una lista de los nombres de los fondos.\n",
    "    n_reps : int, opcional (valor predeterminado = 100)\n",
    "        El número de repeticiones para generar la matriz de pesos aleatoria.\n",
    "\n",
    "    Devuelve:\n",
    "    ---------\n",
    "    tuple\n",
    "        Una tupla que contiene la mejor relación riesgo-recompensa, la asignación de pesos óptima \n",
    "        y una lista de los fondos con asignación de peso no nula.\n",
    "\n",
    "    Notas:\n",
    "    ------\n",
    "    Esta función utiliza el modelo Markoviano para encontrar la asignación de pesos óptima \n",
    "    para un conjunto de fondos dados. Se genera una matriz de pesos aleatoria y se calcula \n",
    "    la relación riesgo-recompensa para cada una de las asignaciones de pesos. La asignación \n",
    "    de pesos con la mejor relación riesgo-recompensa se devuelve junto con la relación \n",
    "    riesgo-recompensa correspondiente y una lista de los fondos con asignación de peso no nula.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convierte la lista de fondos en un array numpy\n",
    "    funds = np.array(funds)\n",
    "\n",
    "    # Obtiene la longitud de los fondos y genera una matriz de pesos aleatoria\n",
    "    long = len(funds)\n",
    "    w = weights_marko(long, n_reps)\n",
    "\n",
    "    # Calcula la rentabilidad media y la matriz de covarianza de los fondos\n",
    "    r_bar = np.array(mean_rents[funds])\n",
    "    mat_cov = df_rents.loc[:, funds].cov()\n",
    "\n",
    "    # Calcula la rentabilidad esperada y la volatilidad para cada asignación de pesos\n",
    "    v_rents = np.dot(w, r_bar)\n",
    "    m1 = np.dot(w, np.array(mat_cov))\n",
    "    v_risk = np.sqrt((m1 * w).sum(axis=1))\n",
    "\n",
    "    # Calcula la relación riesgo-recompensa para cada asignación de pesos\n",
    "    efic = v_rents / v_risk\n",
    "\n",
    "    # Encuentra la asignación de pesos con la mejor relación riesgo-recompensa\n",
    "    best_weight = w[efic.argmax()]\n",
    "    l_fond_0 = funds[best_weight > 0]\n",
    "    best_sharpe = efic[efic.argmax()]\n",
    "\n",
    "    return best_sharpe, best_weight, l_fond_0\n",
    "\n",
    "\n",
    "\n",
    "def select_parents(n_indiv_inic, mean_rents, df_rents, min_fond=1, max_fond=20):\n",
    "    \"\"\"\n",
    "    Selecciona los padres para la siguiente generación.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_indiv_inic : int\n",
    "        Número de individuos iniciales a crear.\n",
    "    min_fond : int, optional\n",
    "        Número mínimo de fondos en la selección de fondos aleatorios, por defecto 1.\n",
    "    max_fond : int, optional\n",
    "        Número máximo de fondos en la selección de fondos aleatorios, por defecto 20.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    parent_funds : numpy.ndarray\n",
    "        Array de fondos de inversión de los padres seleccionados para la siguiente generación.\n",
    "    best_parent : numpy.ndarray\n",
    "        Array de fondos de inversión del mejor padre de la generación actual.\n",
    "    best_parent_sharpe : float\n",
    "        Ratio Sharpe del mejor padre de la generación actual.\n",
    "    \"\"\"\n",
    "\n",
    "    invest_funds = list()\n",
    "    #final_weights = list()\n",
    "    fitness = list()\n",
    "\n",
    "    #n_fond = np.random.randint(min_fond, max_fond, size=n_indiv_inic)\n",
    "    fondos_20 = np.random.choice(df_rents.columns, size=(n_indiv_inic,max_fond))\n",
    "    matrix_01 = np.random.choice([True, False], size=(n_indiv_inic,max_fond))\n",
    "\n",
    "    fondos_20 = fondos_20[matrix_01.sum(axis=1) != 0,:]\n",
    "    matrix_01 = matrix_01[matrix_01.sum(axis=1) != 0,:]\n",
    "\n",
    "    for i in range(len(fondos_20)):\n",
    "        l_fond = fondos_20[i][matrix_01[i]]\n",
    "        #print(f'long inic: {len(l_fond)}')\n",
    "        #l_fond = random.sample(df_close.columns.tolist(), n_fond[i])\n",
    "        sh, _, l_fond_0 = best_marko(l_fond, mean_rents, df_rents)\n",
    "        #print(f'long final: {len(l_fond_0)}')\n",
    "        #print('-------------')\n",
    "        \n",
    "        \n",
    "        fitness.append(sh)\n",
    "        #final_weights.append(w)\n",
    "        invest_funds.append(l_fond_0)\n",
    "\n",
    "    fitness_norm = (np.array(fitness) - min(fitness)) / (max(fitness)-min(fitness))\n",
    "    thresh = random.uniform(0,1)\n",
    "    #print(f'umbral: {thresh}, mediana de fitness_norm {np.median(fitness_norm)}')\n",
    "\n",
    "    fitness_norm = np.array(fitness_norm, dtype=object)\n",
    "    invest_funds = np.array(invest_funds, dtype=object)\n",
    "    #final_weights = np.array(final_weights, dtype=object)\n",
    "\n",
    "    best_parent = invest_funds[fitness_norm.argmax()]\n",
    "    best_parent_sharpe = fitness[fitness_norm.argmax()]\n",
    "\n",
    "    mask_parent = fitness_norm > thresh\n",
    "    parent_funds = invest_funds[mask_parent]\n",
    "    #print(f'longitud de la generacion: {len(parent_funds)}')\n",
    "    #parent_weights = final_weights[mask_parent]\n",
    "\n",
    "    return parent_funds, best_parent, best_parent_sharpe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def combine_nextgen(parent1, l_parent2, df_rents):\n",
    "    \"\"\"\n",
    "    Combina el primer padre con una lista de segundos padres para generar la siguiente generación.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent1 : array-like\n",
    "        Lista de fondos del primer padre.\n",
    "    l_parent2 : array-like\n",
    "        Lista de listas de fondos de los segundos padres.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        Lista de fondos combinados con el padre con el que tiene una mayor correlación.\n",
    "\n",
    "    \"\"\"\n",
    "    val_parent = list()\n",
    "\n",
    "    for p2 in l_parent2:\n",
    "        funds_p = np.union1d(parent1, p2)\n",
    "        val = abs(df_rents.loc[:,funds_p].corr()).mean().mean()\n",
    "        val_parent.append(val)\n",
    "\n",
    "    val_parent = np.array(val_parent)\n",
    "    #print(val_parent)\n",
    "    #print(f'se ha juntado con el padre nº {val_parent.argmin()}')\n",
    "    #print(f'en particular con el {val_parent.argmin()}º')\n",
    "\n",
    "    return np.union1d(parent1, l_parent2[val_parent.argmin()])\n",
    "\n",
    "\n",
    "\n",
    "def generate_couples(parent_funds, df_rents, n_hijos=100, n_azar=3):\n",
    "    \"\"\"\n",
    "    Genera parejas de fondos para la siguiente generación a partir de los padres de la actual generación.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent_funds : array-like\n",
    "        Lista de arrays de fondos de inversión de la generación anterior.\n",
    "    n_hijos : int, optional\n",
    "        Número de parejas de fondos a generar (default is 100).\n",
    "    n_azar : int, optional\n",
    "        Número de padres aleatorios para combinar con cada padre seleccionado (default is 3).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Lista de arrays de fondos de inversión que representan las parejas de fondos de la siguiente generación.\n",
    "    \"\"\"\n",
    "    couples = list()\n",
    "\n",
    "    # Seleccionar padres y candidatos aleatoriamente\n",
    "    padres = np.random.randint(len(parent_funds), size=n_hijos)\n",
    "    candidatos = np.random.randint(len(parent_funds), size=(n_hijos,n_azar))\n",
    "\n",
    "    # Generar parejas de fondos combinando padres y candidatos\n",
    "    for i in range(n_hijos):\n",
    "        parent1 = parent_funds[padres[i]]\n",
    "        #print(f'se ha juntado el: {padres[i]}')\n",
    "        l_parent2 = parent_funds[candidatos[i]]\n",
    "        #print(f'con alguno de los padres {candidatos[i]}')\n",
    "\n",
    "        # Combinar padres y candidatos para generar la nueva pareja de fondos\n",
    "        couple = combine_nextgen(parent1, l_parent2, df_rents) # emparejamiento variado inverso\n",
    "        couples.append(couple)\n",
    "        #print(f'----------------------')\n",
    "\n",
    "    return couples\n",
    "\n",
    "\n",
    "def create_next_gen(best_parent, best_parent_sharpe, couples, mean_rents, df_rents, n_explore=4):\n",
    "    \"\"\"\n",
    "    Crea la siguiente generación de individuos a partir de los padres y las parejas creadas en la generación anterior.\n",
    "\n",
    "    Parámetros:\n",
    "    - best_parent: numpy array de strings. Fondos de inversión que conforman el mejor individuo de la generación anterior.\n",
    "    - best_parent_sharpe: float. Sharpe ratio del mejor individuo de la generación anterior.\n",
    "    - couples: lista de numpy arrays de strings. Pares de fondos de inversión que han sido seleccionados como padres de la siguiente generación.\n",
    "    - n_explore: int. Número de nuevos fondos que se añadirán a cada hijo de la siguiente generación.\n",
    "\n",
    "    Return:\n",
    "    - ng_sharpe: numpy array de floats. Sharpe ratio de cada individuo de la siguiente generación.\n",
    "    - next_gen_funds: numpy array de numpy arrays de strings. Fondos de inversión que conforman cada individuo de la siguiente generación.\n",
    "    \"\"\"\n",
    "    next_gen_funds = list()\n",
    "    ng_sharpe = list()\n",
    "\n",
    "    next_gen_funds.append(best_parent) # el mejor de la generacion anterior\n",
    "    ng_sharpe.append(best_parent_sharpe)\n",
    "\n",
    "    new_fonds = np.random.choice(df_rents.columns.tolist(), size=(len(couples),n_explore)) # los nuevos fondos a explorar\n",
    "\n",
    "    for i in range(len(couples)):\n",
    "        #print(f'la preja es: {couples[i]}')\n",
    "        fond_son = np.union1d(couples[i], new_fonds[i])\n",
    "        #print(f'con los nuevos fondos es: {fond_son}')\n",
    "\n",
    "        sh,w,hijo = best_marko(fond_son,mean_rents,df_rents)\n",
    "        #print(f'tras aplicar markowitz: {hijo}')\n",
    "        #print(f'----------------------')\n",
    "\n",
    "        ng_sharpe.append(sh)\n",
    "        next_gen_funds.append(hijo)\n",
    "\n",
    "    next_gen_funds = np.array(next_gen_funds, dtype=object)\n",
    "    ng_sharpe = np.array(ng_sharpe)\n",
    "\n",
    "    return ng_sharpe, next_gen_funds\n",
    "\n",
    "\n",
    "def select_parents_next_gen(ng_sharpe, next_gen_funds):\n",
    "    \"\"\"\n",
    "    Selecciona los padres para la siguiente generación en función de su\n",
    "    función de aptitud y devuelve el mejor padre de la generación anterior\n",
    "    así como los que han pasado el umbral\n",
    "\n",
    "    Args:\n",
    "    - ng_sharpe (array-like): Array de flotantes que representan el valor Sharpe de cada\n",
    "      cartera en la siguiente generación.\n",
    "    - next_gen_funds (array-like): Array de arrays con los fondos de cada cartera en la\n",
    "      siguiente generación.\n",
    "\n",
    "    Returns:\n",
    "    - parent_funds (array-like): Array de arrays con los fondos de los padres seleccionados.\n",
    "    - best_parent (array): Array con los fondos del mejor padre de la generación anterior.\n",
    "    - best_parent_sharpe (float): Valor Sharpe del mejor padre de la generación anterior.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Normalizar la fitness\n",
    "    fitness_norm = (ng_sharpe - min(ng_sharpe))/(max(ng_sharpe)-min(ng_sharpe))\n",
    "    # Seleccionar un umbral aleatorio\n",
    "    thresh = random.uniform(0,1)\n",
    "    # Crear una máscara booleana para los padres que superan el umbral\n",
    "    mask_thresh = fitness_norm > thresh\n",
    "\n",
    "    # Seleccionar los padres que superan el umbral, el mejor y su fitness\n",
    "    parent_funds = next_gen_funds[mask_thresh]\n",
    "    if len(parent_funds)<5:\n",
    "        while len(parent_funds)<5:\n",
    "            thresh = random.uniform(0,1)\n",
    "            mask_thresh = fitness_norm > thresh\n",
    "            parent_funds = next_gen_funds[mask_thresh]\n",
    "\n",
    "    best_parent = next_gen_funds[fitness_norm.argmax()]\n",
    "    best_parent_sharpe = ng_sharpe[fitness_norm.argmax()]\n",
    "\n",
    "    return parent_funds, best_parent, best_parent_sharpe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['IBE'] 0.12108714639269035\n",
      "{\"date\":\"2019-01-02\",\"result\":true}\n",
      "--------------------------\n",
      "['ACS' 'ANA' 'COL' 'ENC' 'FER' 'TRE'] 1.4898614339532559\n",
      "{\"date\":\"2019-01-23\",\"result\":true}\n",
      "--------------------------\n",
      "['IBE' 'IDR' 'MTS' 'VIS'] 0.5201550853796362\n",
      "{\"date\":\"2019-02-13\",\"result\":true}\n",
      "--------------------------\n",
      "['ACS' 'AENA' 'ELE' 'NTGY' 'SAB' 'TL5'] 1.305905489160157\n",
      "{\"date\":\"2019-03-06\",\"result\":true}\n",
      "--------------------------\n",
      "['ANA' 'BKT' 'CLNX' 'ELE'] 1.2829714802483891\n",
      "{\"date\":\"2019-03-27\",\"result\":true}\n",
      "--------------------------\n",
      "['BBVA' 'ENC' 'IDR' 'ITX' 'SGRE' 'VIS'] 1.0215696715846982\n",
      "{\"date\":\"2019-04-17\",\"result\":true}\n",
      "--------------------------\n",
      "['AENA' 'COL' 'REE' 'TL5'] 0.8191930590913277\n",
      "{\"date\":\"2019-05-13\",\"result\":true}\n",
      "--------------------------\n",
      "['ANA' 'CLNX' 'COL' 'FER' 'IBE'] 0.5791461236723949\n",
      "{\"date\":\"2019-06-03\",\"result\":true}\n",
      "--------------------------\n",
      "['BBVA' 'CIE' 'CLNX' 'GRF' 'IBE' 'ITX' 'SGRE'] 1.2038766646784498\n",
      "{\"date\":\"2019-06-24\",\"result\":true}\n",
      "--------------------------\n",
      "['ANA' 'FER' 'GRF' 'ITX' 'REP' 'TEF'] 1.0311506509573571\n",
      "{\"date\":\"2019-07-15\",\"result\":true}\n",
      "--------------------------\n",
      "['CLNX' 'COL' 'FER' 'GRF' 'NTGY'] 0.17604724330296476\n",
      "{\"date\":\"2019-08-05\",\"result\":true}\n",
      "--------------------------\n",
      "['FER' 'IBE' 'MRL' 'TL5'] 0.8486640561831894\n",
      "{\"date\":\"2019-08-26\",\"result\":true}\n",
      "--------------------------\n",
      "['IBE' 'SGRE' 'TEF'] 2.5512032901441852\n",
      "{\"date\":\"2019-09-16\",\"result\":true}\n",
      "--------------------------\n",
      "['ANA' 'COL' 'GRF' 'MAS'] 1.0274628809785207\n",
      "{\"date\":\"2019-10-07\",\"result\":true}\n",
      "--------------------------\n",
      "['ACX' 'CLNX' 'FER' 'GRF' 'REE'] 1.1047449265722575\n",
      "{\"date\":\"2019-10-28\",\"result\":true}\n",
      "--------------------------\n",
      "['ACX' 'COL' 'ENG' 'GRF' 'IDR' 'MRL'] 0.8531909605629509\n",
      "{\"date\":\"2019-11-18\",\"result\":true}\n",
      "--------------------------\n",
      "['ACX' 'SAB' 'SGRE'] 0.5721485480661362\n",
      "{\"date\":\"2019-12-09\",\"result\":true}\n",
      "--------------------------\n",
      "['ACS' 'ACX' 'BKIA' 'MAS' 'REP'] 0.9453617256936935\n",
      "{\"date\":\"2020-01-02\",\"result\":true}\n",
      "--------------------------\n",
      "['CLNX' 'FER' 'IBE' 'NTGY' 'VIS'] 1.185210890148833\n",
      "{\"date\":\"2020-01-23\",\"result\":true}\n",
      "--------------------------\n",
      "['BBVA' 'CLNX' 'COL' 'ENG' 'GRF' 'IBE'] 0.9510150628937974\n",
      "{\"date\":\"2020-02-13\",\"result\":true}\n",
      "--------------------------\n",
      "['ANA' 'MAS'] 0.39619413690361166\n",
      "{\"date\":\"2020-03-05\",\"result\":true}\n",
      "--------------------------\n",
      "['GRF'] -0.011339613853825073\n",
      "{\"date\":\"2020-03-26\",\"result\":true}\n",
      "--------------------------\n",
      "['CLNX' 'ENC' 'MAS' 'MRL' 'TL5' 'VIS'] 0.9189617570994427\n",
      "{\"date\":\"2020-04-20\",\"result\":true}\n",
      "--------------------------\n",
      "['ACS' 'CLNX' 'TEF' 'VIS'] 0.8574310141393324\n",
      "{\"date\":\"2020-05-12\",\"result\":true}\n",
      "--------------------------\n",
      "['AENA' 'IBE' 'MAS'] 0.7927431808205337\n",
      "{\"date\":\"2020-06-02\",\"result\":true}\n",
      "--------------------------\n",
      "['BKT' 'CLNX'] 0.3369589827795115\n",
      "{\"date\":\"2020-06-23\",\"result\":true}\n",
      "--------------------------\n",
      "['ELE' 'SGRE'] 0.563660860192464\n",
      "{\"date\":\"2020-07-14\",\"result\":true}\n",
      "--------------------------\n",
      "['BKT' 'ITX' 'MRL' 'SGRE' 'VIS'] 0.6521453395550898\n",
      "{\"date\":\"2020-08-04\",\"result\":true}\n",
      "--------------------------\n",
      "['FER' 'MRL' 'SGRE'] 0.5607247616621548\n",
      "{\"date\":\"2020-08-25\",\"result\":true}\n",
      "--------------------------\n",
      "['ALM' 'CIE' 'IDR' 'MTS' 'NTGY' 'SAB'] 0.5370737042832583\n",
      "{\"date\":\"2020-09-15\",\"result\":true}\n",
      "--------------------------\n",
      "['CIE' 'GRF' 'SGRE'] 0.44049392254874836\n",
      "{\"date\":\"2020-10-06\",\"result\":true}\n",
      "--------------------------\n",
      "['ACX' 'ELE' 'SGRE'] 0.1347645275402167\n",
      "{\"date\":\"2020-10-27\",\"result\":true}\n",
      "--------------------------\n",
      "['CABK' 'MTS' 'PHM' 'SGRE' 'VIS'] 0.7694711331169993\n",
      "{\"date\":\"2020-11-17\",\"result\":true}\n",
      "--------------------------\n",
      "['ALM' 'CABK' 'CLNX' 'COL' 'IBE' 'MTS'] 1.1847675611570014\n",
      "{\"date\":\"2020-12-08\",\"result\":true}\n",
      "--------------------------\n",
      "['CIE' 'MEL' 'PHM' 'SGRE' 'SLR'] 1.1975907284624456\n",
      "{\"date\":\"2020-12-30\",\"result\":true}\n",
      "--------------------------\n",
      "['BKT' 'CIE' 'GRF' 'IAG' 'PHM'] 0.8637741656268917\n",
      "{\"date\":\"2021-01-21\",\"result\":true}\n",
      "--------------------------\n",
      "['BBVA' 'CABK' 'PHM'] 0.4459513597071207\n",
      "{\"date\":\"2021-02-11\",\"result\":true}\n",
      "--------------------------\n",
      "['ANA' 'CABK' 'COL' 'IAG' 'VIS'] 1.4599679893196464\n",
      "{\"date\":\"2021-03-04\",\"result\":true}\n",
      "--------------------------\n",
      "['ANA' 'ELE' 'ENG' 'GRF' 'MAP' 'NTGY'] 1.0636377357016158\n",
      "upstream connect error or disconnect/reset before headers. reset reason: connection termination\n",
      "--------------------------\n",
      "['ACS' 'ACX' 'CLNX' 'ENG' 'FDR' 'GRF' 'IBE' 'IDR' 'VIS'] 1.1011164612683382\n",
      "{\"date\":\"2021-04-19\",\"result\":true}\n",
      "--------------------------\n",
      "['CLNX' 'COL' 'FDR' 'IDR' 'SAB'] 1.1318255166988227\n",
      "{\"date\":\"2021-05-10\",\"result\":true}\n",
      "--------------------------\n",
      "['ALM' 'BBVA' 'CLNX' 'ENG' 'REE'] 0.4368948441618525\n",
      "{\"date\":\"2021-05-31\",\"result\":true}\n",
      "--------------------------\n",
      "['CLNX' 'ENG' 'NTGY'] 1.1601002349397354\n",
      "{\"date\":\"2021-06-21\",\"result\":true}\n",
      "--------------------------\n",
      "['ACX' 'SGRE' 'SLR' 'VIS'] 0.5075810235682605\n",
      "{\"date\":\"2021-07-12\",\"result\":true}\n",
      "--------------------------\n",
      "['BKT' 'ENG' 'IDR'] 0.4905942519644223\n",
      "{\"date\":\"2021-08-02\",\"result\":true}\n",
      "--------------------------\n",
      "['ALM' 'BKT' 'CLNX' 'IBE' 'ITX' 'NTGY' 'TEF'] 1.439274143548729\n",
      "{\"date\":\"2021-08-23\",\"result\":true}\n",
      "--------------------------\n",
      "['ACX' 'ANA' 'PHM'] 0.39402272114312914\n",
      "{\"date\":\"2021-09-13\",\"result\":true}\n",
      "--------------------------\n",
      "['AENA' 'IAG' 'REP'] 1.2470648156754132\n",
      "{\"date\":\"2021-10-04\",\"result\":true}\n",
      "--------------------------\n",
      "['ACX' 'ANA' 'CIE' 'REE'] 0.8470524524232759\n",
      "{\"date\":\"2021-10-25\",\"result\":true}\n",
      "--------------------------\n",
      "['AMS' 'BBVA' 'CIE' 'IDR' 'MAP' 'REE'] 1.0635026130260665\n",
      "{\"date\":\"2021-11-15\",\"result\":true}\n",
      "--------------------------\n",
      "['NTGY' 'REE'] 0.400788185413123\n",
      "{\"date\":\"2021-12-03\",\"result\":true}\n",
      "--------------------------\n",
      "['ACX' 'GRF' 'NTGY'] 1.132308859108156\n",
      "{\"date\":\"2021-12-27\",\"result\":true}\n",
      "--------------------------\n",
      "['ACS' 'AENA' 'BBVA' 'BKT' 'CABK' 'ENG' 'PHM' 'REE' 'TEF'] 1.5586795982192028\n",
      "{\"date\":\"2022-01-18\",\"result\":true}\n",
      "--------------------------\n",
      "['ALM' 'SAB' 'TEF'] 0.565964654103628\n",
      "{\"date\":\"2022-02-08\",\"result\":true}\n",
      "--------------------------\n",
      "['GRF' 'IDR' 'PHM' 'REP' 'ROVI'] 0.4977854111214842\n",
      "{\"date\":\"2022-03-01\",\"result\":true}\n",
      "--------------------------\n",
      "['ACS' 'CLNX' 'NTGY' 'SLR'] 0.53945262518683\n",
      "{\"date\":\"2022-03-22\",\"result\":true}\n",
      "--------------------------\n",
      "['ANA' 'FER' 'NTGY' 'PHM' 'REP' 'TEF'] 1.1766790149717818\n",
      "{\"date\":\"2022-04-12\",\"result\":true}\n",
      "--------------------------\n",
      "['AMS' 'ELE' 'GRF' 'MEL' 'REE'] 0.5177205368660227\n",
      "{\"date\":\"2022-05-05\",\"result\":true}\n",
      "--------------------------\n",
      "['CIE' 'ENG' 'MAP' 'SGRE'] 0.835021589653585\n",
      "{\"date\":\"2022-05-26\",\"result\":true}\n",
      "--------------------------\n",
      "['IDR' 'ITX'] 0.1115664835018886\n",
      "{\"date\":\"2022-06-16\",\"result\":true}\n",
      "--------------------------\n",
      "['FER' 'ITX' 'PHM' 'TEF'] 0.867632041715515\n",
      "{\"date\":\"2022-07-07\",\"result\":true}\n",
      "--------------------------\n",
      "['AMS' 'CLNX' 'SGRE'] 0.6491898587409051\n",
      "{\"date\":\"2022-07-28\",\"result\":true}\n",
      "--------------------------\n",
      "['BBVA' 'SAB' 'SGRE'] 1.0339132851992556\n",
      "{\"date\":\"2022-08-18\",\"result\":true}\n",
      "--------------------------\n",
      "['ANE' 'BKT' 'REP'] 0.1992237727119294\n",
      "{\"date\":\"2022-09-08\",\"result\":true}\n",
      "--------------------------\n",
      "['BKT'] 0.19428591332550055\n",
      "{\"date\":\"2022-09-29\",\"result\":true}\n",
      "--------------------------\n",
      "['IDR' 'ITX' 'REP' 'SAB'] 0.6914971855011763\n",
      "{\"date\":\"2022-10-20\",\"result\":true}\n",
      "--------------------------\n",
      "['ACS' 'ANA' 'IDR' 'MAP'] 1.3483262494817465\n",
      "{\"date\":\"2022-11-10\",\"result\":true}\n",
      "--------------------------\n",
      "['CABK' 'FER' 'IBE' 'MAP' 'PHM' 'SAB'] 0.8646387798329667\n",
      "{\"date\":\"2022-12-01\",\"result\":true}\n",
      "--------------------------\n",
      "['CABK' 'FDR' 'IBE' 'IDR' 'SLR'] 0.3513858336901906\n",
      "{\"date\":\"2022-12-22\",\"result\":true}\n",
      "--------------------------\n",
      "['ANA' 'BKT' 'CABK' 'FDR' 'MEL' 'REP'] 1.2994906193427662\n",
      "{\"date\":\"2023-01-13\",\"result\":true}\n",
      "--------------------------\n",
      "['BBVA' 'CLNX' 'FER' 'IAG' 'PHM' 'SAB'] 0.8171731930493777\n",
      "{\"date\":\"2023-02-03\",\"result\":true}\n",
      "--------------------------\n",
      "['IDR' 'MAP' 'NTGY' 'ROVI' 'SCYR' 'TEF'] 1.3526968872950778\n",
      "{\"date\":\"2023-02-24\",\"result\":true}\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "delete_allocs(algo_tag=algo_tag)\n",
    "all_dates = df_close.loc['2019':,:].index\n",
    "\n",
    "for date in all_dates[::15]:\n",
    "    f2 = pd.to_datetime(date)\n",
    "    f1 = f2 - pd.DateOffset(days=20)\n",
    "    #df_small = df_close.loc[f1:f2,:].dropna(axis=1)\n",
    "    #df = np.log(df_small).diff()\n",
    "    df = df_rets.loc[f1:f2,:].dropna(axis=1)\n",
    "    mean_r = df.mean()\n",
    "    n_indiv_inic=400\n",
    "    parent_funds, best_parent, best_parent_sharpe=select_parents(n_indiv_inic=n_indiv_inic, mean_rents=mean_r, df_rents=df, min_fond=1, max_fond=len(mean_r))\n",
    "\n",
    "    n_it = 100\n",
    "    cont = 0\n",
    "    opt = -np.Inf\n",
    "    it = 0\n",
    "\n",
    "    while cont<15 and it<n_it:\n",
    "        it +=1\n",
    "        #print(cont)\n",
    "        couples = generate_couples(parent_funds, df_rents=df, n_hijos=100, n_azar=3)\n",
    "        ng_sharpe, next_gen_funds = create_next_gen(best_parent, best_parent_sharpe, couples, mean_rents=mean_r,df_rents=df, n_explore=4)\n",
    "        parent_funds, best_parent, best_parent_sharpe = select_parents_next_gen(ng_sharpe, next_gen_funds)\n",
    "      \n",
    "        cont += 1\n",
    "\n",
    "        if best_parent_sharpe>opt:\n",
    "            opt = best_parent_sharpe\n",
    "            cont = 0\n",
    "\n",
    "    print(best_parent, best_parent_sharpe)\n",
    "\n",
    "    alloc = 1/len(best_parent)\n",
    "    allocations_to_sent = [\n",
    "                    {'ticker': tck, 'alloc': alloc}\n",
    "                    for tck in best_parent\n",
    "                ]\n",
    "    date = f2.strftime('%Y-%m-%d')\n",
    "    \n",
    "\n",
    "    send_alloc(algo_tag, date, allocations_to_sent)\n",
    "    print('--------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>IBE</th>\n",
       "      <th>ACS</th>\n",
       "      <th>ANA</th>\n",
       "      <th>COL</th>\n",
       "      <th>ENC</th>\n",
       "      <th>FER</th>\n",
       "      <th>TRE</th>\n",
       "      <th>IDR</th>\n",
       "      <th>MTS</th>\n",
       "      <th>VIS</th>\n",
       "      <th>...</th>\n",
       "      <th>PHM</th>\n",
       "      <th>MEL</th>\n",
       "      <th>SLR</th>\n",
       "      <th>IAG</th>\n",
       "      <th>FDR</th>\n",
       "      <th>AMS</th>\n",
       "      <th>MAP</th>\n",
       "      <th>ROVI</th>\n",
       "      <th>ANE</th>\n",
       "      <th>SCYR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02T00:00:00</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-23T00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-13T00:00:00</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-06T00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-27T00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01T00:00:00</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-22T00:00:00</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-13T00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-03T00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-24T00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker                    IBE       ACS       ANA       COL       ENC  \\\n",
       "2019-01-02T00:00:00  1.000000       NaN       NaN       NaN       NaN   \n",
       "2019-01-23T00:00:00       NaN  0.166667  0.166667  0.166667  0.166667   \n",
       "2019-02-13T00:00:00  0.250000       NaN       NaN       NaN       NaN   \n",
       "2019-03-06T00:00:00       NaN  0.166667       NaN       NaN       NaN   \n",
       "2019-03-27T00:00:00       NaN       NaN  0.250000       NaN       NaN   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2022-12-01T00:00:00  0.166667       NaN       NaN       NaN       NaN   \n",
       "2022-12-22T00:00:00  0.200000       NaN       NaN       NaN       NaN   \n",
       "2023-01-13T00:00:00       NaN       NaN  0.166667       NaN       NaN   \n",
       "2023-02-03T00:00:00       NaN       NaN       NaN       NaN       NaN   \n",
       "2023-02-24T00:00:00       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "ticker                    FER       TRE       IDR   MTS   VIS  ...       PHM  \\\n",
       "2019-01-02T00:00:00       NaN       NaN       NaN   NaN   NaN  ...       NaN   \n",
       "2019-01-23T00:00:00  0.166667  0.166667       NaN   NaN   NaN  ...       NaN   \n",
       "2019-02-13T00:00:00       NaN       NaN  0.250000  0.25  0.25  ...       NaN   \n",
       "2019-03-06T00:00:00       NaN       NaN       NaN   NaN   NaN  ...       NaN   \n",
       "2019-03-27T00:00:00       NaN       NaN       NaN   NaN   NaN  ...       NaN   \n",
       "...                       ...       ...       ...   ...   ...  ...       ...   \n",
       "2022-12-01T00:00:00  0.166667       NaN       NaN   NaN   NaN  ...  0.166667   \n",
       "2022-12-22T00:00:00       NaN       NaN  0.200000   NaN   NaN  ...       NaN   \n",
       "2023-01-13T00:00:00       NaN       NaN       NaN   NaN   NaN  ...       NaN   \n",
       "2023-02-03T00:00:00  0.166667       NaN       NaN   NaN   NaN  ...  0.166667   \n",
       "2023-02-24T00:00:00       NaN       NaN  0.166667   NaN   NaN  ...       NaN   \n",
       "\n",
       "ticker                    MEL  SLR       IAG       FDR  AMS       MAP  \\\n",
       "2019-01-02T00:00:00       NaN  NaN       NaN       NaN  NaN       NaN   \n",
       "2019-01-23T00:00:00       NaN  NaN       NaN       NaN  NaN       NaN   \n",
       "2019-02-13T00:00:00       NaN  NaN       NaN       NaN  NaN       NaN   \n",
       "2019-03-06T00:00:00       NaN  NaN       NaN       NaN  NaN       NaN   \n",
       "2019-03-27T00:00:00       NaN  NaN       NaN       NaN  NaN       NaN   \n",
       "...                       ...  ...       ...       ...  ...       ...   \n",
       "2022-12-01T00:00:00       NaN  NaN       NaN       NaN  NaN  0.166667   \n",
       "2022-12-22T00:00:00       NaN  0.2       NaN  0.200000  NaN       NaN   \n",
       "2023-01-13T00:00:00  0.166667  NaN       NaN  0.166667  NaN       NaN   \n",
       "2023-02-03T00:00:00       NaN  NaN  0.166667       NaN  NaN       NaN   \n",
       "2023-02-24T00:00:00       NaN  NaN       NaN       NaN  NaN  0.166667   \n",
       "\n",
       "ticker                   ROVI  ANE      SCYR  \n",
       "2019-01-02T00:00:00       NaN  NaN       NaN  \n",
       "2019-01-23T00:00:00       NaN  NaN       NaN  \n",
       "2019-02-13T00:00:00       NaN  NaN       NaN  \n",
       "2019-03-06T00:00:00       NaN  NaN       NaN  \n",
       "2019-03-27T00:00:00       NaN  NaN       NaN  \n",
       "...                       ...  ...       ...  \n",
       "2022-12-01T00:00:00       NaN  NaN       NaN  \n",
       "2022-12-22T00:00:00       NaN  NaN       NaN  \n",
       "2023-01-13T00:00:00       NaN  NaN       NaN  \n",
       "2023-02-03T00:00:00       NaN  NaN       NaN  \n",
       "2023-02-24T00:00:00  0.166667  NaN  0.166667  \n",
       "\n",
       "[71 rows x 42 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_allocs(algo_tag=algo_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upstream request timeout\n"
     ]
    }
   ],
   "source": [
    "exec_algo(algo_tag=algo_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(annualized_total_return     0.014632\n",
       " alpha_benchmark            -0.005129\n",
       " sharpe_ratio                0.181103\n",
       " n_order/year               23.463704\n",
       " dtype: float64,\n",
       "            time type ticker  n_shares      price      fees  capital_delta\n",
       " 0    2019-01-23  buy    TRE     751.0  22.170000  6.659868  -16656.329868\n",
       " 1    2019-01-23  buy    FER     965.0  17.265197  6.664366  -16667.579471\n",
       " 2    2019-01-23  buy    ENC    2572.0   6.478141  6.664711  -16668.443124\n",
       " 3    2019-01-23  buy    COL    2067.0   8.060311  6.664265  -16667.327102\n",
       " 4    2019-01-23  buy    ANA     230.0  72.429273  6.663493  -16665.396283\n",
       " ..          ...  ...    ...       ...        ...       ...            ...\n",
       " 468  2023-02-24  buy    TEF    5716.0   3.904000  8.926106  -22324.190106\n",
       " 469  2023-02-24  buy   SCYR    7190.0   3.104000  8.927104  -22326.687104\n",
       " 470  2023-02-24  buy   ROVI     540.0  41.280000  8.916480  -22300.116480\n",
       " 471  2023-02-24  buy   NTGY     854.0  26.110000  8.919176  -22306.859176\n",
       " 472  2023-02-24  buy    MAP   11059.0   2.018000  8.926825  -22325.988825\n",
       " \n",
       " [473 rows x 7 columns])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_exec_results(algo_tag=algo_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples = generate_couples(parent_funds, df_rents=df, n_hijos=100, n_azar=3)\n",
    "ng_sharpe, next_gen_funds = create_next_gen(best_parent, best_parent_sharpe, couples, mean_rents=mean_r,df_rents=df, n_explore=4)\n",
    "parent_funds, best_parent, best_parent_sharpe = select_parents_next_gen(ng_sharpe, next_gen_funds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CIE' 'SGRE'] 1.406508174817915\n"
     ]
    }
   ],
   "source": [
    "print(best_parent, best_parent_sharpe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
